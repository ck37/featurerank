---
title: "test"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# remotes::install_github("ck37/ck37r")
library(ck37r)
library(SuperLearner)

ck37r::load_all_code("R", verbose = TRUE)
```

## Data prep

```{r tests}

# TODO: switch to a less problematic demo dataset.
data(Boston, package = "MASS")

set.seed(1, "L'Ecuyer-CMRG")

# Subset rows to speed up example computation.
row_subset = sample(nrow(Boston), 200)

Boston = Boston[row_subset, ]

# Use "chas" as our outcome variable, which is binary.
x = subset(Boston, select = -chas)
y = Boston$chas
family = binomial()

```

## Feature ranking wrappers

Each wrapper should return a ranking of all variables that are being analyzed. They should not do any subsetting.

TODO

* look at Sara Moore's [feature selection repo](https://github.com/saraemoore/SLScreenExtra) for more ideas.
* Also Ron's email about additional feature selection algorithms to try, e.g. from the main paper
* Use tidymodels or mlr3 - do they have good feature selection/ranking options?

```{r fn_feature_ranking}
# TODO:
# univariate correlation 
res1 = featrank_cor(y, x, family)
res1

# random forest
res2 = featrank_randomForest(y, x, family, ntree = 10)
# These aren't named currently.
res2


# TODO: ranger
# TODO: glm (skip? might require a ridge penalty)
# TODO: glmnet (support ridge, lasso, and elastic net)
# TODO: others 
```

### Integrate rankings

```{r integrate_rankings}
# Create a dataframe containing all rankings.
rank_df = data.frame(cor = res1, rf = res2)
rank_df
```

## Aggregation wrappers

This should be one or more was of aggregating multiple feature ranking algorithms, and choosing a cutoff for how many variables to include.

```{r fn_aggregation}
# TODO: reciprocal ranking
agg_reciprocal_rank = function(rank_df) {
  # For each feature, sum the inverse of its ranks, then invert the sum.
  ranks = apply(rank_df, MARGIN = 1, function(row) {
     1 / sum(row^-1)
  })
  return(rank(ranks))
}

# Give it a ranking of multiple algorithms, and it will return the overall ranking.
agg_reciprocal_rank(rank_df)
```

## Overall wrapper

```{r wrapper_overall}
# Specify the data, feature ranking wrappers, aggregation wrapper, and the number
# of features to select.

ensemble_rank =
  function(Y, X, family,
           # Feature ranking algorithms.
           fn_rank = c(featrank_cor, featrank_randomForest),
           # Rank aggregation algorithm.
           fn_agg = agg_reciprocal_rank,
           # How many variables we want to select.
           top_vars = ceiling(ncol(X) / 2),
           # Not used.
           ...)  {
    
    # Run each feature ranking algorithm.
    cat("Run each feature ranking algorithm\n")
    rank_df = do.call(cbind.data.frame,
                      lapply(fn_rank, Y, X, family))
    
    cat("Calculate the aggregate ranking.\n")
    ranking = fn_agg(rank_df)
    
    # Apply the ranking to select the top X variables.
    whichVariable <- (ranking <= top_vars)
    return(whichVariable)
  }

featrank_randomForest10 =  function(...) featrank_randomForest(ntree = 10, ...)


(result = ensemble_rank(y, x, family, fn_rank = c(featrank_cor, featrank_randomForest10)))


```

## Test SuperLearner

```{r test_sl}
# TODO: revise this.
sl = SuperLearner(Boston$chas, X[, 1:3], family = binomial(),
                  cvControl = list(V = 2L, stratifyCV = TRUE),
                  SL.library = c("SL.mean", "SL.glm"))
```
